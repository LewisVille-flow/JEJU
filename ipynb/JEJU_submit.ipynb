{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1JYgL0xh8zvFJN1ATt12l-xXxBdziTLgA","authorship_tag":"ABX9TyNpqP6YhLHeNsL5MeXjbQW5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["# 1. Data setting"],"metadata":{"id":"fhkOdIjZSvde"}},{"cell_type":"code","source":["from xgboost import XGBRegressor\n","from sklearn.metrics import mean_absolute_error\n"],"metadata":{"id":"CXc8tJbPO5mJ","executionInfo":{"status":"ok","timestamp":1668349373726,"user_tz":-540,"elapsed":773,"user":{"displayName":"Joo Hyeong Lee","userId":"16752272692163293320"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","import lightgbm as lgb\n","import gc\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.cluster import KMeans\n","from IPython.display import clear_output \n","\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_absolute_error\n","from xgboost import XGBRegressor\n","\n","from sklearn.metrics import mean_absolute_error\n","\n","import torch\n","'''# font settings for graph visualization\n","plt.rc('font', family='NanumBarunGothic')\n","'''\n","\n","##################### 0. Cuda setting\n","\n","if torch.cuda.is_available():\n","    DEVICE = torch.device('cuda')\n","else:\n","    DEVICE = torch.device('cpu')\n","\n","print('USING pyTorch Version:', torch.__version__, ' Device:', DEVICE)\n","\n","\n","##################### 1. Data Load\n","# run when runtime is disconnected\n","_file_dir = '/content/drive/MyDrive/DACON_contest/DACON_JEJU'\n","\n","\n","train_file_dir = '/content/drive/MyDrive/DACON_contest/DACON_JEJU/train.parquet'\n","test_file_dir = '/content/drive/MyDrive/DACON_contest/DACON_JEJU/test.parquet'\n","\n","train_data_org = pd.read_parquet(train_file_dir)\n","test_data_org = pd.read_parquet(test_file_dir)\n","info_data = pd.read_csv(_file_dir + '/data_info.csv')\n","\n","_save_basic_p_train = _file_dir + '/basic_p_train.pkl'\n","_save_basic_p_test = _file_dir + '/basic_p_test.pkl'\n","\n","train_data = pd.read_pickle(_save_basic_p_train)\n","test_data = pd.read_pickle(_save_basic_p_test)\n","\n","print(\" ### 1. Data load complete ### \")\n","\n","## This is the main code ##\n","\n","##################### 2. set new columns for grouping road names\n","# Train data\n","_road_name_list = list(train_data_org['road_name'].values)\n","train_data_org['road_name_grouped'] = list('0' for i in range(0, len(train_data_org['base_date'].values)))\n","\n","# grouping\n","# 먼저 extra road 를 그룹핑하고, 나머지를 변경한다. \n","_extra_road = list(train_data_org['road_name_grouped'].str.contains('0')) \n","train_data_org.loc[_extra_road, 'road_name_grouped'] = 'extra'\n","\n","_general_road = list(train_data_org['road_name'].str.contains('일반국도')) \n","_country_road = list(train_data_org['road_name'].str.contains('지방도')) \n","_unlabelled_road = list(train_data_org['road_name'].str.contains('-'))\n","\n","train_data_org.loc[_general_road, 'road_name_grouped'] = 'general'\n","train_data_org.loc[_country_road, 'road_name_grouped'] = 'country'\n","train_data_org.loc[_unlabelled_road, 'road_name_grouped'] = 'unlabelled'\n","\n","# Test data\n","_road_name_list_test = list(test_data_org['road_name'].values)\n","test_data_org['road_name_grouped'] = list('0' for i in range(0, len(test_data_org['base_date'].values)))\n","\n","_extra_road_test = list(test_data_org['road_name_grouped'].str.contains('0')) \n","test_data_org.loc[_extra_road_test, 'road_name_grouped'] = 'extra'\n","\n","_general_road_test = list(test_data_org['road_name'].str.contains('일반국도')) \n","_country_road_test = list(test_data_org['road_name'].str.contains('지방도')) \n","_unlabelled_road_test = list(test_data_org['road_name'].str.contains('-'))\n","\n","test_data_org.loc[_general_road_test, 'road_name_grouped'] = 'general'\n","test_data_org.loc[_country_road_test, 'road_name_grouped'] = 'country'\n","test_data_org.loc[_unlabelled_road_test, 'road_name_grouped'] = 'unlabelled'\n","\n","print(\" ### 2. road name grouping complete ### \")\n","\n","##################### 3. Feature Engineering\n","\n","train_data_org['msl_lc'] = train_data_org['maximum_speed_limit'] - (train_data_org['lane_count'] *10)\n","train_data_org['rr_msl'] = -(train_data_org['road_rating']-100) * 2.5 + train_data_org['maximum_speed_limit']\n","\n","test_data_org['msl_lc'] = test_data_org['maximum_speed_limit'] - (test_data_org['lane_count'] *10)\n","test_data_org['rr_msl'] = -(test_data_org['road_rating']-100) * 2.5 + test_data_org['maximum_speed_limit']\n","\n","\n","##################### 3. Split train data\n","# Train\n","train_data_unlabelled = train_data_org[train_data_org['road_name_grouped'] == 'unlabelled']\n","train_data_country = train_data_org[train_data_org['road_name_grouped'] == 'country']\n","train_data_extra = train_data_org[train_data_org['road_name_grouped'] == 'extra']\n","train_data_general = train_data_org[train_data_org['road_name_grouped'] == 'general']\n","\n","# Test\n","test_data_unlabelled = test_data_org[test_data_org['road_name_grouped'] == 'unlabelled']\n","test_data_country = test_data_org[test_data_org['road_name_grouped'] == 'country']\n","test_data_extra = test_data_org[test_data_org['road_name_grouped'] == 'extra']\n","test_data_general = test_data_org[test_data_org['road_name_grouped'] == 'general']\n","\n","print(\" ### 3. Data split by road-name-grouped complete ###\")\n","\n","# Label encoding - +1하는 이유는 0을 없애기 위해서.\n","str_col = ['day_of_week','start_turn_restricted','end_turn_restricted', 'start_node_name', 'end_node_name', 'road_name', 'road_name_grouped']\n","for i in str_col:\n","    le = LabelEncoder()\n","    le=le.fit(train_data_org[i])\n","    train_data_org[i] = le.transform(train_data_org[i]) + 1\n","    \n","    for label in np.unique(test_data_org[i]):\n","        if label not in le.classes_: \n","            le.classes_ = np.append(le.classes_, label)\n","    test_data_org[i] = le.transform(test_data_org[i]) + 1\n","\n","print(\"\\tshape of train: {} \\tshape of test: {}\".format(train_data_org.shape, test_data_org.shape))\n","print(\" ### 4. Feature Label encoding complete ### \")\n","\n","##################### 5. Feature Engineering Plus(피처 추가)\n","\n","# month and day of week\n","## str(object) 만to_datetime 이 된다. 그래서 변환 후 설정해줌...\n","train_data_org['base_date'] = pd.to_datetime(train_data_org['base_date'].apply(str))\n","train_data_org['Month'] = train_data_org['base_date'].dt.month\n","train_data_org['Day_of_week'] = train_data_org['base_date'].dt.weekday\n","\n","test_data_org['base_date'] = pd.to_datetime(test_data_org['base_date'].apply(str))\n","test_data_org['Month'] = test_data_org['base_date'].dt.month\n","test_data_org['Day_of_week'] = test_data_org['base_date'].dt.weekday\n","\n","# weekdays and weekends\n","_issunday = list(train_data_org['base_date'].dt.weekday == 6)\n","_issaturday = list(train_data_org['base_date'].dt.weekday == 5)\n","_isweekends = [sun + sat for sun, sat in zip(_issunday, _issaturday)]\n","train_data_org['IsWeekends'] = _isweekends\n","\n","_issunday = list(test_data_org['base_date'].dt.weekday == 6)\n","_issaturday = list(test_data_org['base_date'].dt.weekday == 5)\n","_isweekends = [sun + sat for sun, sat in zip(_issunday, _issaturday)]\n","test_data_org['IsWeekends'] = _isweekends\n","\n","# hour grouping(새벽, 출근, 오후, 퇴근)\n","## train\n","_time_1_1 = list(train_data_org['base_hour'] >= 22)\n","_time_1_2 = list(train_data_org['base_hour'] < 6)\n","_time_1 = [1 if a == True or b == True else 0 for a, b in zip(_time_1_1, _time_1_2)] # 23을 넘어가면 and가 안된다...\n","\n","_time_2_1 = list(train_data_org['base_hour'] >= 6)\n","_time_2_2 = list(train_data_org['base_hour'] < 11)\n","_time_2 = [2 if a == True and b == True else 0 for a, b in zip(_time_2_1, _time_2_2)]   # \n","\n","_time_3_1 = list(train_data_org['base_hour'] >= 11)\n","_time_3_2 = list(train_data_org['base_hour'] < 17)\n","_time_3 = [3 if a == True and b == True else 0 for a, b in zip(_time_3_1, _time_3_2)] # \n","\n","_time_4_1 = list(train_data_org['base_hour'] >= 17)\n","_time_4_2 = list(train_data_org['base_hour'] < 22)\n","_time_4 = [4 if a == True and b == True else 0 for a, b in zip(_time_4_1, _time_4_2)]  # \n","\n","_time_sum = [a + b + c + d for a, b, c, d in zip(_time_1, _time_2, _time_3, _time_4)]  # summary\n","\n","train_data_org['Hour_grouped'] = _time_sum\n","\n","## test\n","_time_1_1 = list(test_data_org['base_hour'] >= 22)\n","_time_1_2 = list(test_data_org['base_hour'] < 6)\n","_time_1 = [1 if a == True or b == True else 0 for a, b in zip(_time_1_1, _time_1_2)] # 23을 넘어가면 and가 안된다...\n","\n","_time_2_1 = list(test_data_org['base_hour'] >= 6)\n","_time_2_2 = list(test_data_org['base_hour'] < 11)\n","_time_2 = [2 if a == True and b == True else 0 for a, b in zip(_time_2_1, _time_2_2)]   # \n","\n","_time_3_1 = list(test_data_org['base_hour'] >= 11)\n","_time_3_2 = list(test_data_org['base_hour'] < 17)\n","_time_3 = [3 if a == True and b == True else 0 for a, b in zip(_time_3_1, _time_3_2)] # \n","\n","_time_4_1 = list(test_data_org['base_hour'] >= 17)\n","_time_4_2 = list(test_data_org['base_hour'] < 22)\n","_time_4 = [4 if a == True and b == True else 0 for a, b in zip(_time_4_1, _time_4_2)]  # \n","\n","_time_sum = [a + b + c + d for a, b, c, d in zip(_time_1, _time_2, _time_3, _time_4)]  # summary\n","\n","test_data_org['Hour_grouped'] = _time_sum\n","\n","# distance from city\n","## train\n","_distance_jeju_s = list(round((((train_data_org['start_latitude'] - 33.4996)*60*1.85)**2 + ((train_data_org['start_longitude'] - 126.5312)*60*1.85)**2),3))\n","train_data_org['Dist_from_JEJU_s'] = _distance_jeju_s\n","\n","_distance_jeju_e = list(round((((train_data_org['end_latitude'] - 33.4996)*60*1.85)**2 + ((train_data_org['end_longitude'] - 126.5312)*60*1.85)**2),3))\n","train_data_org['Dist_from_JEJU_e'] = _distance_jeju_e\n","\n","_distance_seogwipo_s = list(round((((train_data_org['start_latitude'] - 33.2541)*60*1.85)**2 + ((train_data_org['start_longitude'] - 126.5601)*60*1.85)**2) ,3))\n","train_data_org['Dist_from_Seogwipo_s'] = _distance_seogwipo_s\n","\n","_distance_seogwipo_e = list(round((((train_data_org['end_latitude'] - 33.2541)*60*1.85)**2 + ((train_data_org['end_longitude'] - 126.5601)*60*1.85)**2),3))\n","train_data_org['Dist_from_Seogwipo_e'] = _distance_seogwipo_e\n","\n","## test\n","_distance_jeju_s = list(round((((test_data_org['start_latitude'] - 33.4996)*60*1.85)**2 + ((test_data_org['start_longitude'] - 126.5312)*60*1.85)**2),3))\n","test_data_org['Dist_from_JEJU_s'] = _distance_jeju_s\n","\n","_distance_jeju_e = list(round((((test_data_org['end_latitude'] - 33.4996)*60*1.85)**2 + ((test_data_org['end_longitude'] - 126.5312)*60*1.85)**2),3))\n","test_data_org['Dist_from_JEJU_e'] = _distance_jeju_e\n","\n","_distance_seogwipo_s = list(round((((test_data_org['start_latitude'] - 33.2541)*60*1.85)**2 + ((test_data_org['start_longitude'] - 126.5601)*60*1.85)**2) ,3))\n","test_data_org['Dist_from_Seogwipo_s'] = _distance_seogwipo_s\n","\n","_distance_seogwipo_e = list(round((((test_data_org['end_latitude'] - 33.2541)*60*1.85)**2 + ((test_data_org['end_longitude'] - 126.5601)*60*1.85)**2),3))\n","test_data_org['Dist_from_Seogwipo_e'] = _distance_seogwipo_e\n","\n","# 도로 이름의 속도 평균, 중앙 값 (약 50초)\n","\n","_road_name_encoded_list = list(train_data_org.road_name.unique())\n","\n","for i in range(0, len(_road_name_encoded_list)):\n","    ## 해당 도로 속도 평균, max, min 구하기\n","    _road_name_encoded = _road_name_encoded_list[i]\n","    _correspond_road_pd = train_data_org[train_data_org['road_name'] == _road_name_encoded]\n","    _target_list = np.array(list(_correspond_road_pd['target']))\n","\n","    _target_average = round(np.mean(_target_list), 3)\n","    _target_median = round(np.median(_target_list), 3)\n","    _target_max = round(np.max(_target_list), 3)\n","    _target_min = round(np.min(_target_list), 3)\n","    _target_max_min_dif = round(abs(_target_max - _target_min), 3)\n","\n","    ## 컬럼 추가하기\n","    _corresond_road_list_train = list(train_data_org['road_name'] == _road_name_encoded)\n","    train_data_org.loc[_corresond_road_list_train, 'target_avg'] = _target_average\n","    train_data_org.loc[_corresond_road_list_train, 'target_med'] = _target_median\n","\n","    _corresond_road_list_test = list(test_data_org['road_name'] == _road_name_encoded)\n","    test_data_org.loc[_corresond_road_list_test, 'target_avg'] = _target_average\n","    test_data_org.loc[_corresond_road_list_test, 'target_med'] = _target_median\n","\n","\n","# 6. 시간 * start_longitude\n","## train\n","_base_hour_list_train = list(train_data_org['base_hour'])\n","_base_hour_dawn_train = [100 if a == 0 or a == 4 else 30 for a in _base_hour_list_train]\n","_slong_list_train = list(train_data_org['start_longitude'] - 126)\n","_hour_mul_slong_train = [a*b for a, b in zip(_base_hour_dawn_train, _slong_list_train)]\n","\n","train_data_org['hour_mul_slong'] = _hour_mul_slong_train\n","\n","## test\n","_base_hour_list_test = list(test_data_org['base_hour'])\n","_base_hour_dawn_test = [100 if a == 0 or a == 4 else 30 for a in _base_hour_list_test]\n","_slong_list_test = list(test_data_org['start_longitude'] - 126)\n","_hour_mul_slong_test = [a*b for a, b in zip(_base_hour_dawn_test, _slong_list_test)]\n","\n","test_data_org['hour_mul_slong'] = _hour_mul_slong_test\n","\n","\n","# 시간 * 시청으로부터의 거리\n","\n","_hour_mul_slong_j_train = [a*b for a, b in zip(_base_hour_dawn_train, list(train_data_org['Dist_from_JEJU_s']))]\n","train_data_org['hour_mul_dist_j'] = _hour_mul_slong_j_train\n","\n","_hour_mul_slong_s_train = [a*b for a, b in zip(_base_hour_dawn_train, list(train_data_org['Dist_from_Seogwipo_s']))]\n","train_data_org['hour_mul_dist_s'] = _hour_mul_slong_s_train\n","\n","_hour_mul_slong_j_test = [a*b for a, b in zip(_base_hour_dawn_test, list(test_data_org['Dist_from_JEJU_s']))]\n","test_data_org['hour_mul_dist_j'] = _hour_mul_slong_j_test\n","\n","_hour_mul_slong_s_test = [a*b for a, b in zip(_base_hour_dawn_test, list(test_data_org['Dist_from_Seogwipo_s']))]\n","test_data_org['hour_mul_dist_s'] = _hour_mul_slong_s_test\n","\n","\n","# lane_count * road_name\n","train_data_org['lanecount_mul_name'] = train_data_org['lane_count']**2 * train_data_org['road_name']\n","test_data_org['lanecount_mul_name'] = test_data_org['lane_count']**2 * test_data_org['road_name']\n","\n","\n","train_data_org = train_data_org.drop(['id', 'road_in_use', 'height_restricted', 'multi_linked', 'base_date', 'vehicle_restricted','connect_code'], axis=1)\n","test_data_org = test_data_org.drop(['id', 'road_in_use', 'height_restricted', 'multi_linked', 'base_date', 'vehicle_restricted', 'connect_code'], axis=1)\n","\n","\n","_len_1 = len(train_data_org[train_data_org['road_name_grouped'] == 1])\n","_len_2 = len(train_data_org[train_data_org['road_name_grouped'] == 2])\n","_len_3 = len(train_data_org[train_data_org['road_name_grouped'] == 3])\n","_len_4 = len(train_data_org[train_data_org['road_name_grouped'] == 4])\n","\n","_road_group_list = [_len_1, _len_2, _len_3, _len_4]\n","\n","print(\"length of road name group 1~4: {}, {}, {}, {}\".format(_len_1, _len_2, _len_3, _len_4))\n","\n","for idx, i in enumerate(_road_group_list):\n","    if(i == 698704):\n","        print(\"number {} is country\".format(idx+1))\n","        _country_idx = idx+1\n","    elif(i == 1285567):\n","        print(\"number {} is extra\".format(idx+1))\n","        _extra_idx = idx+1\n","    elif(i == 2147483):\n","        print(\"number {} is general\".format(idx+1))\n","        _general_idx = idx+1\n","    elif(i == 569463):\n","        print(\"number {} is unlabelled\".format(idx+1))\n","        _unlabelled_idx = idx+1\n","\n","print(\" ### 5. Feature Engineering (some features added) complete ### \")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6L7KCDNMPHGS","executionInfo":{"status":"ok","timestamp":1668349851685,"user_tz":-540,"elapsed":103463,"user":{"displayName":"Joo Hyeong Lee","userId":"16752272692163293320"}},"outputId":"84c6ad2a-9e20-49a4-acd1-825ae233126d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["USING pyTorch Version: 1.12.1+cu113  Device: cuda\n"," ### 1. Data load complete ### \n"," ### 2. road name grouping complete ### \n"," ### 3. Data split by road-name-grouped complete ###\n","\tshape of train: (4701217, 27) \tshape of test: (291241, 26)\n"," ### 4. Feature Label encoding complete ### \n","length of road name group 1~4: 698704, 1285567, 2147483, 569463\n","number 1 is country\n","number 2 is extra\n","number 3 is general\n","number 4 is unlabelled\n"," ### 5. Feature Engineering (some features added) complete ### \n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"FNnsIZssXxOm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Model trianing XGB"],"metadata":{"id":"N33Uky8zSsa7"}},{"cell_type":"code","source":["from xgboost import XGBRegressor\n","from sklearn.metrics import mean_absolute_error\n","\n","##### Road general\n","\n","#1. general\n","# Trial 0 finished with value: 3.0178409360571536 and parameters: \n","# {'n_estimators': 1098, 'max_depth': 13, 'min_child_weight': 69, 'gamma': 2, \n","# 'colsample_bytree': 0.8, 'lambda': 0.00013294769198806425, 'alpha': 0.018851716895628944, 'subsample': 0.6}. \n","\n","\n","train_data_general_optuna = train_data_org[train_data_org['road_name_grouped'] == _general_idx]\n","\n","X_g = train_data_general_optuna.drop(['target'], axis=1)\n","Y_g = train_data_general_optuna['target']\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(X_g, Y_g, test_size=0.1, shuffle=True, random_state=11)\n","print('X_train shape: {}, \\tX_valid shape: {},\\ny_train shape: {}, \\ty_valid shape: {}'.format(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape))\n","\n","XGB_general = XGBRegressor(gpu_id = 0, tree_method='gpu_hist', n_jobs=-1, n_estimators=1098, \n","                           max_depth=13, min_child_weight=69, gamma=2, colsample_bytree=0.8, reg_lambda=0.000133, \n","                           reg_alpha=0.0189, subsample=0.6, verbosity=1).fit(X_train, y_train)\n","\n","valid_pred = XGB_general.predict(X_valid)\n","MAE = mean_absolute_error(y_valid, valid_pred)\n","print('y_valid prediction MAE of general idx is {}'.format(MAE))\n"],"metadata":{"id":"oM6yogByRbni","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ce486e16-0975-4417-e54c-f605e160ea07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape: (1932734, 33), \tX_valid shape: (214749, 33),\n","y_train shape: (1932734,), \ty_valid shape: (214749,)\n","[14:28:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"]}]},{"cell_type":"code","source":["##### Road country\n","\n","# Trial 1 finished with value: 2.881378921865521 and parameters: {'n_estimators': 1975, 'max_depth': 7, 'min_child_weight': 250, \n","# 'gamma': 5, 'colsample_bytree': 1.0, 'lambda': 0.014419524884176096, 'alpha': 1.1394561107249395, 'subsample': 1.0}. Best is trial 0 with value: 2.748566196751375.\n","\n","# 2. country\n","# Trial 3 finished with value: 2.719350625520355 and parameters: \n","# {'n_estimators': 3190, 'max_depth': 14, 'min_child_weight': 18, 'gamma': 3, 'colsample_bytree': 0.6, 'lambda': 0.005825596412374463, 'alpha': 0.1807523789855458, 'subsample': 0.8}. \n","# Best is trial 3 with value: 2.719350625520355.\n","# 아주 매력적인 숫자인데 ㅋㅋ 아쉽군 xgboost가 오래걸리는 모델같음\n","# 그래서 lightGBM으로 튜닝하고 싶었는데 너무 오래걸리더라 튜닝이\n","# 그래서 안하고 그냥 저 튜닝된 숫자(xgb)로 모델 학습시켜서 내려고했는데 이지경 ㅠㅡㅠ\n","# 아마 xgboost 이거 gpu 안쓰나?\n","train_data_country_optuna = train_data_org[train_data_org['road_name_grouped'] == _country_idx]\n","\n","X_c = train_data_country_optuna.drop(['target'], axis=1)\n","Y_c = train_data_country_optuna['target']\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(X_c, Y_c, test_size=0.1, shuffle=True, random_state=11)\n","print('X_train shape: {}, \\tX_valid shape: {},\\ny_train shape: {}, \\ty_valid shape: {}'.format(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape))\n","\n","XGB_country = XGBRegressor(gpu_id = 0, tree_method='gpu_hist', n_jobs=-1, n_estimators=1975, max_depth=7, min_child_weight=250, gamma=5, \n","                           colsample_bytree=1.0, reg_lambda=0.01442, reg_alpha=1.13946, subsample=1.0, verbosity=2).fit(X_train, y_train)\n","\n","valid_pred = XGB_country.predict(X_valid)\n","\n","MAE = mean_absolute_error(y_valid, valid_pred)\n","print('y_valid prediction MAE of country idx is {}'.format(MAE))"],"metadata":{"id":"7MShZzhmRblv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668349878125,"user_tz":-540,"elapsed":26446,"user":{"displayName":"Joo Hyeong Lee","userId":"16752272692163293320"}},"outputId":"26d3ccd3-1e6a-42e6-b93e-6bdbf43eef4c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape: (628833, 33), \tX_valid shape: (69871, 33),\n","y_train shape: (628833,), \ty_valid shape: (69871,)\n","[14:30:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","y_valid prediction MAE of country idx is 2.768038034647235\n"]}]},{"cell_type":"code","source":["##### Road Extra\n","\n","# 3. extra\n","# 그냥 lightGBM -> 3.8정도였던듯.\n","# Best trial: score 3.3106561411088897,\n","# params {'n_estimators': 2573, 'max_depth': 13, 'min_child_weight': 142, 'gamma': 1, \n","# 'colsample_bytree': 0.6, 'lambda': 0.002211116337529265, 'alpha': 5.5786841254307905e-05, 'subsample': 0.8}\n","\n","\n","train_data_extra_optuna = train_data_org[train_data_org['road_name_grouped'] == _extra_idx]\n","\n","X_e = train_data_extra_optuna.drop(['target'], axis=1)\n","Y_e = train_data_extra_optuna['target']\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(X_e, Y_e, test_size=0.1, shuffle=True, random_state=11)\n","print('X_train shape: {}, \\tX_valid shape: {},\\ny_train shape: {}, \\ty_valid shape: {}'.format(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape))\n","\n","XGB_extra = XGBRegressor(gpu_id = 0, tree_method='gpu_hist', n_jobs=-1, n_estimators=2573, max_depth=13, min_child_weight=142, gamma=1, \n","                           colsample_bytree=0.6, reg_lambda=0.00221, reg_alpha=5.5787e-05, subsample=0.8, verbosity=1).fit(X_train, y_train)\n","\n","valid_pred = XGB_extra.predict(X_valid)\n","\n","MAE = mean_absolute_error(y_valid, valid_pred)\n","print('y_valid prediction MAE of extra idx is {}'.format(MAE))"],"metadata":{"id":"o8xbO895RbkQ","colab":{"base_uri":"https://localhost:8080/","height":507},"executionInfo":{"status":"error","timestamp":1668349916611,"user_tz":-540,"elapsed":38490,"user":{"displayName":"Joo Hyeong Lee","userId":"16752272692163293320"}},"outputId":"0a684aeb-01e5-4475-8848-22297515f85e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape: (1157010, 33), \tX_valid shape: (128557, 33),\n","y_train shape: (1157010,), \ty_valid shape: (128557,)\n","[14:31:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-cc9140f5d360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m XGB_extra = XGBRegressor(gpu_id = 0, tree_method='gpu_hist', n_jobs=-1, n_estimators=2573, max_depth=13, min_child_weight=142, gamma=1, \n\u001b[0;32m---> 19\u001b[0;31m                            colsample_bytree=0.6, reg_lambda=0.00221, reg_alpha=5.5787e-05, subsample=0.8, verbosity=1).fit(X_train, y_train)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mvalid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGB_extra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["##### Road Unlabelled\n","\n","# 4. unlabelled\n","# Best trial: score 2.9646844485918584,\n","# params {'n_estimators': 3065, 'max_depth': 12, 'min_child_weight': 74, 'gamma': 1, \n","# 'colsample_bytree': 1.0, 'lambda': 1.613367056357903e-05, 'alpha': 6.689301433489457, 'subsample': 1.0}\n","\n","train_data_unlabelled_optuna = train_data_org[train_data_org['road_name_grouped'] == _unlabelled_idx]\n","\n","X_u = train_data_unlabelled_optuna.drop(['target'], axis=1)\n","Y_u = train_data_unlabelled_optuna['target']\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(X_u, Y_u, test_size=0.1, shuffle=True, random_state=11)\n","print('X_train shape: {}, \\tX_valid shape: {},\\ny_train shape: {}, \\ty_valid shape: {}'.format(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape))\n","\n","XGB_unlabelled = XGBRegressor(gpu_id = 0, tree_method='gpu_hist', n_jobs=-1, n_estimators=3065, max_depth=12, min_child_weight=74, gamma=1, \n","                           colsample_bytree=1.0, reg_lambda=1.613e-05, reg_alpha=6.6893, subsample=1.0).fit(X_train, y_train)\n","\n","valid_pred = XGB_unlabelled.predict(X_valid)\n","\n","MAE = mean_absolute_error(y_valid, valid_pred)\n","print('y_valid prediction MAE of unlabelled idx is {}'.format(MAE))"],"metadata":{"id":"Y7Wsu5JMTYlu","colab":{"base_uri":"https://localhost:8080/","height":507},"executionInfo":{"status":"error","timestamp":1668349934185,"user_tz":-540,"elapsed":12973,"user":{"displayName":"Joo Hyeong Lee","userId":"16752272692163293320"}},"outputId":"c4731d94-f4c1-4327-ba92-fbd27d8a7197"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape: (512516, 33), \tX_valid shape: (56947, 33),\n","y_train shape: (512516,), \ty_valid shape: (56947,)\n","[14:32:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-5fa34e53d297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m XGB_unlabelled = XGBRegressor(gpu_id = 0, tree_method='gpu_hist', n_jobs=-1, n_estimators=3065, max_depth=12, min_child_weight=74, gamma=1, \n\u001b[0;32m---> 17\u001b[0;31m                            colsample_bytree=1.0, reg_lambda=1.613e-05, reg_alpha=6.6893, subsample=1.0).fit(X_train, y_train)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mvalid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGB_unlabelled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# 제출용 - 각 road 별 idx 리스트 만들기\n","test_data_org_general_idx = list(test_data_org[test_data_org['road_name_grouped'] == _general_idx].index)\n","test_data_org_country_idx = list(test_data_org[test_data_org['road_name_grouped'] == _country_idx].index)\n","test_data_org_extra_idx = list(test_data_org[test_data_org['road_name_grouped'] == _extra_idx].index)\n","test_data_org_unlabelled_idx =list(test_data_org[test_data_org['road_name_grouped'] == _unlabelled_idx].index)\n","\n","# 테스트 데이터 - 각 road 별 데이터 뽑기\n","test_data_org_general = test_data_org[test_data_org['road_name_grouped'] == _general_idx]\n","test_data_org_country = test_data_org[test_data_org['road_name_grouped'] == _country_idx]\n","test_data_org_extra = test_data_org[test_data_org['road_name_grouped'] == _extra_idx]\n","test_data_org_unlabelled = test_data_org[test_data_org['road_name_grouped'] == _unlabelled_idx]\n","\n","# 테스트 데이터에 예측 값 계산하기\n","submit_pred_general = XGB_general.predict(test_data_org_general)\n","submit_pred_country = XGB_country.predict(test_data_org_country)\n","submit_pred_extra = XGB_extra.predict(test_data_org_extra)\n","submit_pred_unlabelled = XGB_unlabelled.predict(test_data_org_unlabelled)\n","\n","# 제출 파일에 덮어쓰기\n","sample_dir = '/content/drive/MyDrive/DACON_contest/DACON_JEJU' + '/sample_submission.csv'\n","\n","sample_submission = pd.read_csv(sample_dir)\n","print(\"submission org length: \", len(sample_submission))\n","sample_submission.loc[test_data_org_general_idx, 'target'] = submit_pred_general\n","sample_submission.loc[test_data_org_country_idx, 'target'] = submit_pred_country\n","sample_submission.loc[test_data_org_extra_idx, 'target'] = submit_pred_extra\n","sample_submission.loc[test_data_org_unlabelled_idx, 'target'] = submit_pred_unlabelled\n","\n","# 덮어쓴 파일 저장하기\n","sample_submission.to_csv(\"/content/drive/MyDrive/DACON_contest/DACON_JEJU/submit_1113_xgb_optuna_1.csv\", index = False)"],"metadata":{"id":"SDxgAcBnTaD7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668349958598,"user_tz":-540,"elapsed":1592,"user":{"displayName":"Joo Hyeong Lee","userId":"16752272692163293320"}},"outputId":"6953f087-2032-4841-d04b-57d2fa2e7851"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["submission length:  291241\n"]}]},{"cell_type":"code","source":["### 시간이 남는다면 이 모델도 돌려서 저장하고싶어요\n","##### Road country\n","\n","train_data_country_optuna = train_data_org[train_data_org['road_name_grouped'] == _country_idx]\n","\n","X_c2 = train_data_country_optuna.drop(['target'], axis=1)\n","Y_c2 = train_data_country_optuna['target']\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(X_c2, Y_c2, test_size=0.1, shuffle=True, random_state=11)\n","print('X_train shape: {}, \\tX_valid shape: {},\\ny_train shape: {}, \\ty_valid shape: {}'.format(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape))\n","\n","XGB_country_2 = XGBRegressor(gpu_id = 0, tree_method='gpu_hist', n_jobs=-1, n_estimators=3190, max_depth=14, min_child_weight=18, gamma=3, \n","                           colsample_bytree=0.6, reg_lambda=0.005826, reg_alpha=0.18075, subsample=0.8).fit(X_train, y_train)\n","\n","valid_pred = XGB_country_2.predict(X_valid)\n","\n","MAE = mean_absolute_error(y_valid, valid_pred)\n","print('y_valid prediction MAE of country2 idx is {}'.format(MAE))"],"metadata":{"id":"ZQ1ECxBXYXOV"},"execution_count":null,"outputs":[]}]}